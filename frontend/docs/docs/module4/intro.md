---
sidebar_position: 1
---

# Module 4: Vision-Language-Action (VLA) & Capstone

The final module brings together everything you've learned to create an integrated humanoid robot system.

## Overview

In this capstone module, we'll combine vision, language, and action to create sophisticated robotic behaviors:

- Voice Command Interface: Implementing OpenAI Whisper
- Cognitive Planning: LLMs as Action Planners (Natural Language to ROS 2)
- Capstone Project: Building the Autonomous Humanoid (Integration)

## What You'll Learn

By the end of this module, you'll understand how to:

- Integrate voice recognition with robotic control
- Use large language models for cognitive planning
- Translate natural language commands to robot actions
- Build a complete autonomous humanoid system

Let's bring it all together in the capstone project!